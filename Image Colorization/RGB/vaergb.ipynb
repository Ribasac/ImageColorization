{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VAE RGB","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport keras.layers as layers\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow_probability as tfp\nimport tensorflow_addons as tfa","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-19T08:36:22.336010Z","iopub.execute_input":"2023-04-19T08:36:22.337073Z","iopub.status.idle":"2023-04-19T08:36:32.211376Z","shell.execute_reply.started":"2023-04-19T08:36:22.337024Z","shell.execute_reply":"2023-04-19T08:36:32.210248Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, MaxPooling2D, UpSampling2D, Concatenate\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint \nfrom keras.utils import plot_model\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.213562Z","iopub.execute_input":"2023-04-19T08:36:32.215897Z","iopub.status.idle":"2023-04-19T08:36:32.222878Z","shell.execute_reply.started":"2023-04-19T08:36:32.215853Z","shell.execute_reply":"2023-04-19T08:36:32.221143Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.filters import threshold_otsu\nfrom glob import glob\nfrom scipy import misc\nfrom matplotlib.patches import Circle,Ellipse\nfrom matplotlib.patches import Rectangle","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.225578Z","iopub.execute_input":"2023-04-19T08:36:32.226307Z","iopub.status.idle":"2023-04-19T08:36:32.649232Z","shell.execute_reply.started":"2023-04-19T08:36:32.226269Z","shell.execute_reply":"2023-04-19T08:36:32.648128Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport scipy.misc\nimport imageio\nfrom skimage.transform import rescale, resize\nfrom skimage.color import lab2rgb","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.652021Z","iopub.execute_input":"2023-04-19T08:36:32.652521Z","iopub.status.idle":"2023-04-19T08:36:32.722620Z","shell.execute_reply.started":"2023-04-19T08:36:32.652479Z","shell.execute_reply":"2023-04-19T08:36:32.721329Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\nimport gzip","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.725682Z","iopub.execute_input":"2023-04-19T08:36:32.726838Z","iopub.status.idle":"2023-04-19T08:36:32.732767Z","shell.execute_reply.started":"2023-04-19T08:36:32.726801Z","shell.execute_reply":"2023-04-19T08:36:32.731553Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom keras import backend as K\nimport tensorflow_addons as tfa\nimport tensorflow as tf\n\n'''batch_size= 8\nimage_size = [120, 120]\n\n\nds = image_dataset_from_directory(\n    '/kaggle/input/imagedataset/data',\n    labels=None,\n    image_size=image_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True,\n    color_mode='grayscale'\n)\n\ndef convert_to_float(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n\ndef trans1(img):\n    return tfa.image.rotate(tf.image.flip_left_right(tf.image.flip_up_down(img)),-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans2(img):\n    return tfa.image.rotate(img,-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans3(img):\n    return tfa.image.rotate(img,.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n    \nds1,ds2,ds3,ds4 = ds,ds.map(trans1),ds.map(trans2),ds.map(trans3)\n\nds = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nx = (\n    ds\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)'''","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.734491Z","iopub.execute_input":"2023-04-19T08:36:32.734913Z","iopub.status.idle":"2023-04-19T08:36:32.748273Z","shell.execute_reply.started":"2023-04-19T08:36:32.734874Z","shell.execute_reply":"2023-04-19T08:36:32.747023Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'batch_size= 8\\nimage_size = [120, 120]\\n\\n\\nds = image_dataset_from_directory(\\n    \\'/kaggle/input/imagedataset/data\\',\\n    labels=None,\\n    image_size=image_size,\\n    interpolation=\\'nearest\\',\\n    batch_size=batch_size,\\n    shuffle=True,\\n    color_mode=\\'grayscale\\'\\n)\\n\\ndef convert_to_float(image):\\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\\n    return image\\n\\n\\ndef trans1(img):\\n    return tfa.image.rotate(tf.image.flip_left_right(tf.image.flip_up_down(img)),-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\\n\\ndef trans2(img):\\n    return tfa.image.rotate(img,-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\\n\\ndef trans3(img):\\n    return tfa.image.rotate(img,.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\\n    \\nds1,ds2,ds3,ds4 = ds,ds.map(trans1),ds.map(trans2),ds.map(trans3)\\n\\nds = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\\n\\nAUTOTUNE = tf.data.experimental.AUTOTUNE\\nx = (\\n    ds\\n    .map(convert_to_float)\\n    .cache()\\n    .prefetch(buffer_size=AUTOTUNE)\\n)'"},"metadata":{}}]},{"cell_type":"code","source":"ab_path = \"/kaggle/input/image-colorization/ab/ab/ab1.npy\"\nl_path = \"/kaggle/input/image-colorization/l/gray_scale.npy\"","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.750483Z","iopub.execute_input":"2023-04-19T08:36:32.750864Z","iopub.status.idle":"2023-04-19T08:36:32.761057Z","shell.execute_reply.started":"2023-04-19T08:36:32.750828Z","shell.execute_reply":"2023-04-19T08:36:32.760152Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ab_df = np.load(ab_path)[0:3000]\nL_df = np.load(l_path)[0:3000]\ndataset = (L_df,ab_df )\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:32.762439Z","iopub.execute_input":"2023-04-19T08:36:32.762923Z","iopub.status.idle":"2023-04-19T08:36:53.555650Z","shell.execute_reply.started":"2023-04-19T08:36:32.762885Z","shell.execute_reply":"2023-04-19T08:36:53.554512Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"code","source":"rgb_df = []","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:53.556947Z","iopub.execute_input":"2023-04-19T08:36:53.557627Z","iopub.status.idle":"2023-04-19T08:36:53.562519Z","shell.execute_reply.started":"2023-04-19T08:36:53.557583Z","shell.execute_reply":"2023-04-19T08:36:53.561439Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for i in range(0,3000):\n    img = np.zeros((224,224,3))\n    img[:,:,0] = L_df[i]\n    img[:,:,1:] = ab_df[i]\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    rgb_df.append(img)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:53.567440Z","iopub.execute_input":"2023-04-19T08:36:53.568435Z","iopub.status.idle":"2023-04-19T08:36:57.140184Z","shell.execute_reply.started":"2023-04-19T08:36:53.568397Z","shell.execute_reply":"2023-04-19T08:36:57.139131Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"rgb_df = np.array(rgb_df)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:57.141868Z","iopub.execute_input":"2023-04-19T08:36:57.142576Z","iopub.status.idle":"2023-04-19T08:36:57.283188Z","shell.execute_reply.started":"2023-04-19T08:36:57.142538Z","shell.execute_reply":"2023-04-19T08:36:57.282146Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,16,2):\n    plt.subplot(4,4,i)\n    img = np.zeros((224,224,3))\n    img[:,:,0] = L_df[i]\n    plt.title('B&W')\n    plt.imshow(lab2rgb(img))\n    \n    plt.subplot(4,4,i+1)\n    img = rgb_df[i]\n    plt.title('Colored')\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:36:57.284904Z","iopub.execute_input":"2023-04-19T08:36:57.285441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 224\nbatch_size = 64\nINPUT_DIM = (img_size,img_size,1)\nZ_DIM = 64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ab_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"x = []\ny = []\ndef read_images(data): #method to read images\n    for i in range(len(data)):\n        rgb_image = Image.open( data[i] ).resize( ( img_size , img_size ) )\n        # Normalize the RGB image array\n        rgb_img_array = (np.asarray( rgb_image ) ) / 255\n        gray_image = rgb_image.convert( 'L' )\n        # Normalize the grayscale image array\n        gray_img_array = ( np.asarray( gray_image ).reshape( ( img_size , img_size , 1 ) ) ) / 255\n        # Append both the image arrays\n        x.append( gray_img_array )\n        y.append( rgb_img_array )\n    return x,y\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"x, y = read_images(data) #calling readimage\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = (L_df/255).astype('float32') \ny = (rgb_df/255).astype('float32') ","metadata":{"execution":{"iopub.status.idle":"2023-04-19T08:37:05.708222Z","shell.execute_reply.started":"2023-04-19T08:37:02.199540Z","shell.execute_reply":"2023-04-19T08:37:05.707143Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"del ab_df","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:05.709746Z","iopub.execute_input":"2023-04-19T08:37:05.710030Z","iopub.status.idle":"2023-04-19T08:37:05.717929Z","shell.execute_reply.started":"2023-04-19T08:37:05.710003Z","shell.execute_reply":"2023-04-19T08:37:05.715967Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(y[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:05.719511Z","iopub.execute_input":"2023-04-19T08:37:05.720145Z","iopub.status.idle":"2023-04-19T08:37:05.745317Z","shell.execute_reply.started":"2023-04-19T08:37:05.720107Z","shell.execute_reply":"2023-04-19T08:37:05.744260Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split( x , y , test_size=0.1, random_state=42 )","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:05.746948Z","iopub.execute_input":"2023-04-19T08:37:05.747519Z","iopub.status.idle":"2023-04-19T08:37:06.441542Z","shell.execute_reply.started":"2023-04-19T08:37:05.747474Z","shell.execute_reply":"2023-04-19T08:37:06.440380Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        mean_mu, log_var = inputs\n        epsilon = tf.random.normal(shape=tf.shape(mean_mu), mean=0., stddev=1.) \n        return mean_mu + tf.math.exp(log_var/2)*epsilon ","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:06.443050Z","iopub.execute_input":"2023-04-19T08:37:06.443437Z","iopub.status.idle":"2023-04-19T08:37:06.451399Z","shell.execute_reply.started":"2023-04-19T08:37:06.443399Z","shell.execute_reply":"2023-04-19T08:37:06.450360Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"lrelu = tf.nn.selu","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:06.453373Z","iopub.execute_input":"2023-04-19T08:37:06.453662Z","iopub.status.idle":"2023-04-19T08:37:06.462225Z","shell.execute_reply.started":"2023-04-19T08:37:06.453636Z","shell.execute_reply":"2023-04-19T08:37:06.461256Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def build_vae_encoder(input_dim, output_dim):\n    \n    # Clear tensorflow session to reset layer index numbers to 0 for LeakyRelu, \n    # BatchNormalization and Dropout.\n    # Otherwise, the names of above mentioned layers in the model \n    # would be inconsistent\n    global K\n    K.clear_session()\n    \n\n    # Define model input\n    encoder_input = Input(shape = input_dim, name = 'encoder_input')\n    x = encoder_input\n\n    # Add convolutional layers\n    conv1 = Conv2D( 8 , kernel_size=( 5 , 5 ) , strides=1 )( x )\n    conv1 = LeakyReLU()( conv1 )\n    conv1 = Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n    conv1 = LeakyReLU()( conv1 )\n    conv1 = Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n    conv1 = LeakyReLU()( conv1 )\n\n    conv2 = Conv2D( 16 , kernel_size=( 5 , 5 ) , strides=1)( conv1 )\n    conv2 = LeakyReLU()( conv2 )\n    conv2 = Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n    conv2 = LeakyReLU()( conv2 )\n    conv2 = Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n    conv2 = LeakyReLU()( conv2 )\n\n    conv3 = Conv2D( 32 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n    conv3 = LeakyReLU()( conv3 )\n    conv3 = Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n    conv3 = LeakyReLU()( conv3 )\n    conv3 = Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n    conv3 = LeakyReLU()( conv3 )\n\n    # Required for reshaping latent vector while building Decoder\n    shape_before_flattening = K.int_shape(conv3)[1:] \n    \n    x = Flatten()(conv3)\n    \n    mean_mu = Dense(64, name = 'mu')(x)\n    log_var = Dense(64, name = 'log_var')(x)\n\n    # Using a Keras Lambda Layer to include the sampling function as a layer \n    # in the model\n    z = Sampling()([mean_mu, log_var])\n    cshape1 = tf.shape(conv1)[2]\n    cshape2 = tf.shape(conv2)[2]\n    cshape3 = tf.shape(conv3)[2]\n\n    return encoder_input, [z, conv3, conv2, conv1], [cshape1, cshape2, cshape3], mean_mu, log_var , shape_before_flattening, Model(inputs = encoder_input, outputs = [mean_mu, log_var, z, conv3, conv2, conv1])","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:06.463975Z","iopub.execute_input":"2023-04-19T08:37:06.464338Z","iopub.status.idle":"2023-04-19T08:37:06.477168Z","shell.execute_reply.started":"2023-04-19T08:37:06.464302Z","shell.execute_reply":"2023-04-19T08:37:06.476265Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"vae_encoder_input, vae_encoder_output, cshape, mean_mu, log_var, vae_shape_before_flattening, encoder  = build_vae_encoder(input_dim = INPUT_DIM,\n                                    output_dim = Z_DIM)\n\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:06.478572Z","iopub.execute_input":"2023-04-19T08:37:06.478926Z","iopub.status.idle":"2023-04-19T08:37:09.462101Z","shell.execute_reply.started":"2023-04-19T08:37:06.478877Z","shell.execute_reply":"2023-04-19T08:37:09.461301Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n encoder_input (InputLayer)     [(None, 224, 224, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 220, 220, 8)  208         ['encoder_input[0][0]']          \n                                                                                                  \n leaky_re_lu (LeakyReLU)        (None, 220, 220, 8)  0           ['conv2d[0][0]']                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 218, 218, 16  1168        ['leaky_re_lu[0][0]']            \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_1 (LeakyReLU)      (None, 218, 218, 16  0           ['conv2d_1[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 216, 216, 16  2320        ['leaky_re_lu_1[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_2 (LeakyReLU)      (None, 216, 216, 16  0           ['conv2d_2[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 212, 212, 16  6416        ['leaky_re_lu_2[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_3 (LeakyReLU)      (None, 212, 212, 16  0           ['conv2d_3[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 210, 210, 32  4640        ['leaky_re_lu_3[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_4 (LeakyReLU)      (None, 210, 210, 32  0           ['conv2d_4[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 208, 208, 32  9248        ['leaky_re_lu_4[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_5 (LeakyReLU)      (None, 208, 208, 32  0           ['conv2d_5[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 204, 204, 32  25632       ['leaky_re_lu_5[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_6 (LeakyReLU)      (None, 204, 204, 32  0           ['conv2d_6[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 202, 202, 64  18496       ['leaky_re_lu_6[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_7 (LeakyReLU)      (None, 202, 202, 64  0           ['conv2d_7[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 200, 200, 64  36928       ['leaky_re_lu_7[0][0]']          \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_8 (LeakyReLU)      (None, 200, 200, 64  0           ['conv2d_8[0][0]']               \n                                )                                                                 \n                                                                                                  \n flatten (Flatten)              (None, 2560000)      0           ['leaky_re_lu_8[0][0]']          \n                                                                                                  \n mu (Dense)                     (None, 64)           163840064   ['flatten[0][0]']                \n                                                                                                  \n log_var (Dense)                (None, 64)           163840064   ['flatten[0][0]']                \n                                                                                                  \n sampling (Sampling)            (None, 64)           0           ['mu[0][0]',                     \n                                                                  'log_var[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 327,785,184\nTrainable params: 327,785,184\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_decoder(input_dim, shape_before_flattening):\n\n    # Define model input\n    decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n    conv3 = Input(shape = (200,200,64,) , name = 'conv3')\n    conv2 = Input(shape = (208,208,32,) , name = 'conv2')\n    conv1 = Input(shape = (216,216,16,) , name = 'conv1')\n\n    # To get an exact mirror image of the encoder\n    x = Dense(np.prod(shape_before_flattening))(decoder_input)\n    x = Reshape(shape_before_flattening)(x)\n\n    # Add convolutional layers\n    concat_1 = Concatenate()( [ x , conv3 ] )\n    conv_up_3 = Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 )( concat_1 )\n    conv_up_3 = LeakyReLU()( conv_up_3 )\n    conv_up_3 = Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv_up_3 )\n    conv_up_3 = LeakyReLU()( conv_up_3 )\n    conv_up_3 = Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 )( conv_up_3 )\n    conv_up_3 = LeakyReLU()( conv_up_3 )\n\n    concat_2 = Concatenate()( [ conv_up_3 , conv2 ] )\n    conv_up_2 = Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 )( concat_2 )\n    conv_up_2 = LeakyReLU()( conv_up_2 )\n    conv_up_2 = Conv2DTranspose( 16 , kernel_size=( 3 , 3 ) , strides=1 )( conv_up_2 )\n    conv_up_2 = LeakyReLU()( conv_up_2 )\n    conv_up_2 = Conv2DTranspose( 16 , kernel_size=( 5 , 5 ) , strides=1 )( conv_up_2 )\n    conv_up_2 = LeakyReLU()( conv_up_2 )\n\n    concat_3 = Concatenate()( [ conv_up_2 , conv1 ] )\n    conv_up_1 = Conv2DTranspose( 16 , kernel_size=( 3 , 3 ) , strides=1 )( concat_3 )\n    conv_up_1 = LeakyReLU()( conv_up_1 )\n    conv_up_1 = Conv2DTranspose( 8 , kernel_size=( 3 , 3 ) , strides=1 )( conv_up_1 )\n    conv_up_1 = LeakyReLU()( conv_up_1 )\n    x = Conv2DTranspose( 3 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu')( conv_up_1 )\n\n    # Define model output\n    decoder_output = x\n\n    return [decoder_input, conv3, conv2, conv1], decoder_output, Model(inputs = [decoder_input, conv3, conv2, conv1], outputs = decoder_output)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.463572Z","iopub.execute_input":"2023-04-19T08:37:09.463930Z","iopub.status.idle":"2023-04-19T08:37:09.496093Z","shell.execute_reply.started":"2023-04-19T08:37:09.463892Z","shell.execute_reply":"2023-04-19T08:37:09.495169Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"vae_decoder_input, vae_decoder_output, decoder = build_decoder(input_dim = Z_DIM,\n                                        shape_before_flattening = vae_shape_before_flattening\n                                        )\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.497283Z","iopub.execute_input":"2023-04-19T08:37:09.497607Z","iopub.status.idle":"2023-04-19T08:37:09.770128Z","shell.execute_reply.started":"2023-04-19T08:37:09.497569Z","shell.execute_reply":"2023-04-19T08:37:09.769301Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n decoder_input (InputLayer)     [(None, 64)]         0           []                               \n                                                                                                  \n dense (Dense)                  (None, 2560000)      166400000   ['decoder_input[0][0]']          \n                                                                                                  \n reshape (Reshape)              (None, 200, 200, 64  0           ['dense[0][0]']                  \n                                )                                                                 \n                                                                                                  \n conv3 (InputLayer)             [(None, 200, 200, 6  0           []                               \n                                4)]                                                               \n                                                                                                  \n concatenate (Concatenate)      (None, 200, 200, 12  0           ['reshape[0][0]',                \n                                8)                                'conv3[0][0]']                  \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 202, 202, 64  73792      ['concatenate[0][0]']            \n ose)                           )                                                                 \n                                                                                                  \n leaky_re_lu_9 (LeakyReLU)      (None, 202, 202, 64  0           ['conv2d_transpose[0][0]']       \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 204, 204, 64  36928      ['leaky_re_lu_9[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n leaky_re_lu_10 (LeakyReLU)     (None, 204, 204, 64  0           ['conv2d_transpose_1[0][0]']     \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 208, 208, 32  51232      ['leaky_re_lu_10[0][0]']         \n spose)                         )                                                                 \n                                                                                                  \n leaky_re_lu_11 (LeakyReLU)     (None, 208, 208, 32  0           ['conv2d_transpose_2[0][0]']     \n                                )                                                                 \n                                                                                                  \n conv2 (InputLayer)             [(None, 208, 208, 3  0           []                               \n                                2)]                                                               \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 208, 208, 64  0           ['leaky_re_lu_11[0][0]',         \n                                )                                 'conv2[0][0]']                  \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 210, 210, 32  18464      ['concatenate_1[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n leaky_re_lu_12 (LeakyReLU)     (None, 210, 210, 32  0           ['conv2d_transpose_3[0][0]']     \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_4 (Conv2DTran  (None, 212, 212, 16  4624       ['leaky_re_lu_12[0][0]']         \n spose)                         )                                                                 \n                                                                                                  \n leaky_re_lu_13 (LeakyReLU)     (None, 212, 212, 16  0           ['conv2d_transpose_4[0][0]']     \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_5 (Conv2DTran  (None, 216, 216, 16  6416       ['leaky_re_lu_13[0][0]']         \n spose)                         )                                                                 \n                                                                                                  \n leaky_re_lu_14 (LeakyReLU)     (None, 216, 216, 16  0           ['conv2d_transpose_5[0][0]']     \n                                )                                                                 \n                                                                                                  \n conv1 (InputLayer)             [(None, 216, 216, 1  0           []                               \n                                6)]                                                               \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 216, 216, 32  0           ['leaky_re_lu_14[0][0]',         \n                                )                                 'conv1[0][0]']                  \n                                                                                                  \n conv2d_transpose_6 (Conv2DTran  (None, 218, 218, 16  4624       ['concatenate_2[0][0]']          \n spose)                         )                                                                 \n                                                                                                  \n leaky_re_lu_15 (LeakyReLU)     (None, 218, 218, 16  0           ['conv2d_transpose_6[0][0]']     \n                                )                                                                 \n                                                                                                  \n conv2d_transpose_7 (Conv2DTran  (None, 220, 220, 8)  1160       ['leaky_re_lu_15[0][0]']         \n spose)                                                                                           \n                                                                                                  \n leaky_re_lu_16 (LeakyReLU)     (None, 220, 220, 8)  0           ['conv2d_transpose_7[0][0]']     \n                                                                                                  \n conv2d_transpose_8 (Conv2DTran  (None, 224, 224, 3)  603        ['leaky_re_lu_16[0][0]']         \n spose)                                                                                           \n                                                                                                  \n==================================================================================================\nTotal params: 166,597,843\nTrainable params: 166,597,843\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"lr = 0.00005","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.771196Z","iopub.execute_input":"2023-04-19T08:37:09.771572Z","iopub.status.idle":"2023-04-19T08:37:09.777593Z","shell.execute_reply.started":"2023-04-19T08:37:09.771530Z","shell.execute_reply":"2023-04-19T08:37:09.776659Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def r_accuracy(img_original, img_reconstructed):\n    mse = tf.reduce_mean((img_original - img_reconstructed) ** 2)\n    pixel_max = 1.0\n    psnr = 20 * tf.math.log(pixel_max / tf.math.sqrt(mse))/tf.math.log(10.0)\n    return psnr","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.784122Z","iopub.execute_input":"2023-04-19T08:37:09.791724Z","iopub.status.idle":"2023-04-19T08:37:09.810689Z","shell.execute_reply.started":"2023-04-19T08:37:09.791685Z","shell.execute_reply":"2023-04-19T08:37:09.809793Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n        self.r_accuracy_tracker = keras.metrics.Mean(name=\"r_accuracy\")\n        self.r_accuracy = r_accuracy\n        \n        \n    def call(self,x):\n        z_mean, z_log_var, z, conv3, conv2, conv1 = self.encoder(x)\n        reconstruction = self.decoder([z, conv3, conv2, conv1])\n        return reconstruction\n\n    \n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n            self.r_accuracy_tracker,\n        ]\n\n    def train_step(self, data):\n        x, y = data\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z, conv3, conv2, conv1 = self.encoder(x)\n            reconstruction = self.decoder([z, conv3, conv2, conv1])\n            reconstruction_loss = tf.reduce_mean(tf.math.square(y - reconstruction), axis=[1, 2, 3])\n            kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.math.square(z_mean) - tf.math.exp(z_log_var), axis = 1)\n            kl_loss = tf.reduce_mean(kl_loss)\n            #coorelation_loss = corr_loss(z)\n            \n            total_loss = 10000*reconstruction_loss + kl_loss\n            r_accuracy = self.r_accuracy(y, reconstruction)\n\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        self.r_accuracy_tracker.update_state(r_accuracy)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n            \"r_accuracy\": self.r_accuracy_tracker.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.812112Z","iopub.execute_input":"2023-04-19T08:37:09.813668Z","iopub.status.idle":"2023-04-19T08:37:09.826480Z","shell.execute_reply.started":"2023-04-19T08:37:09.813639Z","shell.execute_reply":"2023-04-19T08:37:09.825446Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model1 = VAE(encoder,decoder)\nmodel1.compile(optimizer=keras.optimizers.Adam(learning_rate = lr))","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.828669Z","iopub.execute_input":"2023-04-19T08:37:09.828928Z","iopub.status.idle":"2023-04-19T08:37:09.875092Z","shell.execute_reply.started":"2023-04-19T08:37:09.828900Z","shell.execute_reply":"2023-04-19T08:37:09.874128Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"history = model1.fit(train_x, train_y, epochs=100, batch_size=32, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T07:15:18.239626Z","iopub.execute_input":"2023-04-19T07:15:18.239911Z","iopub.status.idle":"2023-04-19T08:31:47.926613Z","shell.execute_reply.started":"2023-04-19T07:15:18.239885Z","shell.execute_reply":"2023-04-19T08:31:47.924615Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/100\n85/85 [==============================] - 46s 537ms/step - loss: 978.2533 - reconstruction_loss: 0.0689 - kl_loss: 10.3998 - r_accuracy: 12.1228\nEpoch 3/100\n85/85 [==============================] - 46s 538ms/step - loss: 383.3588 - reconstruction_loss: 0.0358 - kl_loss: 4.4946 - r_accuracy: 14.5057\nEpoch 4/100\n85/85 [==============================] - 46s 537ms/step - loss: 319.9316 - reconstruction_loss: 0.0301 - kl_loss: 1.6491 - r_accuracy: 15.2514\nEpoch 5/100\n85/85 [==============================] - 46s 539ms/step - loss: 276.7305 - reconstruction_loss: 0.0264 - kl_loss: 0.9356 - r_accuracy: 15.8197\nEpoch 6/100\n85/85 [==============================] - 46s 538ms/step - loss: 253.0694 - reconstruction_loss: 0.0249 - kl_loss: 0.5182 - r_accuracy: 16.0776\nEpoch 7/100\n85/85 [==============================] - 46s 538ms/step - loss: 240.7261 - reconstruction_loss: 0.0241 - kl_loss: 0.5841 - r_accuracy: 16.2117\nEpoch 8/100\n85/85 [==============================] - 46s 538ms/step - loss: 237.4886 - reconstruction_loss: 0.0235 - kl_loss: 0.6200 - r_accuracy: 16.3082\nEpoch 9/100\n85/85 [==============================] - 46s 537ms/step - loss: 235.6237 - reconstruction_loss: 0.0228 - kl_loss: 0.6643 - r_accuracy: 16.4446\nEpoch 10/100\n85/85 [==============================] - 46s 539ms/step - loss: 223.6565 - reconstruction_loss: 0.0222 - kl_loss: 0.9922 - r_accuracy: 16.5698\nEpoch 11/100\n85/85 [==============================] - 46s 537ms/step - loss: 219.5688 - reconstruction_loss: 0.0215 - kl_loss: 1.5634 - r_accuracy: 16.7150\nEpoch 12/100\n85/85 [==============================] - 46s 536ms/step - loss: 207.4448 - reconstruction_loss: 0.0207 - kl_loss: 2.4273 - r_accuracy: 16.8665\nEpoch 13/100\n85/85 [==============================] - 46s 537ms/step - loss: 196.2383 - reconstruction_loss: 0.0199 - kl_loss: 3.1825 - r_accuracy: 17.0512\nEpoch 14/100\n85/85 [==============================] - 45s 535ms/step - loss: 195.6037 - reconstruction_loss: 0.0190 - kl_loss: 4.0697 - r_accuracy: 17.2337\nEpoch 15/100\n85/85 [==============================] - 46s 538ms/step - loss: 188.6794 - reconstruction_loss: 0.0183 - kl_loss: 4.4880 - r_accuracy: 17.4078\nEpoch 16/100\n85/85 [==============================] - 46s 538ms/step - loss: 181.0600 - reconstruction_loss: 0.0178 - kl_loss: 4.8277 - r_accuracy: 17.5425\nEpoch 17/100\n85/85 [==============================] - 46s 537ms/step - loss: 175.9543 - reconstruction_loss: 0.0171 - kl_loss: 5.4974 - r_accuracy: 17.6925\nEpoch 18/100\n85/85 [==============================] - 46s 538ms/step - loss: 172.1502 - reconstruction_loss: 0.0166 - kl_loss: 5.6361 - r_accuracy: 17.8317\nEpoch 19/100\n85/85 [==============================] - 46s 537ms/step - loss: 169.1195 - reconstruction_loss: 0.0161 - kl_loss: 6.0047 - r_accuracy: 17.9658\nEpoch 20/100\n85/85 [==============================] - 46s 537ms/step - loss: 162.3704 - reconstruction_loss: 0.0155 - kl_loss: 6.1196 - r_accuracy: 18.1227\nEpoch 21/100\n85/85 [==============================] - 46s 538ms/step - loss: 159.9190 - reconstruction_loss: 0.0151 - kl_loss: 6.6694 - r_accuracy: 18.2333\nEpoch 22/100\n85/85 [==============================] - 46s 538ms/step - loss: 154.5400 - reconstruction_loss: 0.0147 - kl_loss: 6.5790 - r_accuracy: 18.3487\nEpoch 23/100\n85/85 [==============================] - 45s 533ms/step - loss: 148.4216 - reconstruction_loss: 0.0142 - kl_loss: 6.6901 - r_accuracy: 18.4907\nEpoch 24/100\n85/85 [==============================] - 46s 535ms/step - loss: 144.4601 - reconstruction_loss: 0.0139 - kl_loss: 7.0102 - r_accuracy: 18.6145\nEpoch 25/100\n85/85 [==============================] - 46s 537ms/step - loss: 143.2842 - reconstruction_loss: 0.0135 - kl_loss: 7.0121 - r_accuracy: 18.7061\nEpoch 26/100\n85/85 [==============================] - 46s 539ms/step - loss: 138.5266 - reconstruction_loss: 0.0132 - kl_loss: 7.3001 - r_accuracy: 18.8523\nEpoch 27/100\n85/85 [==============================] - 46s 537ms/step - loss: 134.3797 - reconstruction_loss: 0.0128 - kl_loss: 7.5516 - r_accuracy: 18.9367\nEpoch 28/100\n85/85 [==============================] - 46s 538ms/step - loss: 134.0915 - reconstruction_loss: 0.0125 - kl_loss: 7.4005 - r_accuracy: 19.0507\nEpoch 29/100\n85/85 [==============================] - 46s 537ms/step - loss: 131.3804 - reconstruction_loss: 0.0122 - kl_loss: 7.3774 - r_accuracy: 19.1651\nEpoch 30/100\n85/85 [==============================] - 46s 539ms/step - loss: 128.9831 - reconstruction_loss: 0.0120 - kl_loss: 7.3892 - r_accuracy: 19.2497\nEpoch 31/100\n85/85 [==============================] - 46s 537ms/step - loss: 122.9373 - reconstruction_loss: 0.0117 - kl_loss: 7.6511 - r_accuracy: 19.3553\nEpoch 32/100\n85/85 [==============================] - 46s 538ms/step - loss: 121.0898 - reconstruction_loss: 0.0115 - kl_loss: 7.6754 - r_accuracy: 19.4261\nEpoch 33/100\n85/85 [==============================] - 46s 537ms/step - loss: 120.0326 - reconstruction_loss: 0.0113 - kl_loss: 7.7587 - r_accuracy: 19.5026\nEpoch 34/100\n85/85 [==============================] - 46s 537ms/step - loss: 117.8237 - reconstruction_loss: 0.0110 - kl_loss: 7.6909 - r_accuracy: 19.6086\nEpoch 35/100\n85/85 [==============================] - 46s 537ms/step - loss: 116.3337 - reconstruction_loss: 0.0109 - kl_loss: 7.7494 - r_accuracy: 19.6521\nEpoch 36/100\n85/85 [==============================] - 46s 538ms/step - loss: 119.3850 - reconstruction_loss: 0.0109 - kl_loss: 7.9103 - r_accuracy: 19.6509\nEpoch 37/100\n85/85 [==============================] - 46s 537ms/step - loss: 113.3545 - reconstruction_loss: 0.0105 - kl_loss: 7.6764 - r_accuracy: 19.8236\nEpoch 38/100\n85/85 [==============================] - 46s 538ms/step - loss: 110.0808 - reconstruction_loss: 0.0103 - kl_loss: 7.8322 - r_accuracy: 19.8840\nEpoch 39/100\n85/85 [==============================] - 46s 537ms/step - loss: 110.1975 - reconstruction_loss: 0.0101 - kl_loss: 7.7155 - r_accuracy: 19.9686\nEpoch 40/100\n85/85 [==============================] - 45s 535ms/step - loss: 107.8533 - reconstruction_loss: 0.0100 - kl_loss: 8.0259 - r_accuracy: 20.0273\nEpoch 41/100\n85/85 [==============================] - 46s 537ms/step - loss: 106.5422 - reconstruction_loss: 0.0098 - kl_loss: 8.0040 - r_accuracy: 20.1411\nEpoch 42/100\n85/85 [==============================] - 46s 535ms/step - loss: 104.2613 - reconstruction_loss: 0.0095 - kl_loss: 8.0440 - r_accuracy: 20.2483\nEpoch 43/100\n85/85 [==============================] - 46s 537ms/step - loss: 102.5332 - reconstruction_loss: 0.0093 - kl_loss: 8.1537 - r_accuracy: 20.3541\nEpoch 44/100\n85/85 [==============================] - 46s 537ms/step - loss: 98.3558 - reconstruction_loss: 0.0091 - kl_loss: 8.1441 - r_accuracy: 20.4362\nEpoch 45/100\n85/85 [==============================] - 46s 538ms/step - loss: 98.3192 - reconstruction_loss: 0.0090 - kl_loss: 8.1875 - r_accuracy: 20.4859\nEpoch 46/100\n85/85 [==============================] - 46s 537ms/step - loss: 96.4740 - reconstruction_loss: 0.0088 - kl_loss: 8.2040 - r_accuracy: 20.5763\nEpoch 47/100\n85/85 [==============================] - 46s 536ms/step - loss: 94.6105 - reconstruction_loss: 0.0087 - kl_loss: 8.2663 - r_accuracy: 20.6349\nEpoch 48/100\n85/85 [==============================] - 46s 537ms/step - loss: 93.7187 - reconstruction_loss: 0.0086 - kl_loss: 8.2176 - r_accuracy: 20.7148\nEpoch 49/100\n85/85 [==============================] - 46s 536ms/step - loss: 94.0437 - reconstruction_loss: 0.0085 - kl_loss: 8.2523 - r_accuracy: 20.7476\nEpoch 50/100\n85/85 [==============================] - 46s 537ms/step - loss: 93.0093 - reconstruction_loss: 0.0084 - kl_loss: 8.4972 - r_accuracy: 20.7854\nEpoch 51/100\n85/85 [==============================] - 46s 537ms/step - loss: 90.6213 - reconstruction_loss: 0.0082 - kl_loss: 8.1855 - r_accuracy: 20.9024\nEpoch 52/100\n85/85 [==============================] - 46s 535ms/step - loss: 88.7650 - reconstruction_loss: 0.0080 - kl_loss: 8.3829 - r_accuracy: 20.9717\nEpoch 53/100\n85/85 [==============================] - 46s 537ms/step - loss: 89.1144 - reconstruction_loss: 0.0079 - kl_loss: 8.5216 - r_accuracy: 21.0475\nEpoch 54/100\n85/85 [==============================] - 46s 537ms/step - loss: 85.3036 - reconstruction_loss: 0.0078 - kl_loss: 8.2874 - r_accuracy: 21.1196\nEpoch 55/100\n85/85 [==============================] - 46s 538ms/step - loss: 87.5203 - reconstruction_loss: 0.0078 - kl_loss: 8.4796 - r_accuracy: 21.1236\nEpoch 56/100\n85/85 [==============================] - 46s 538ms/step - loss: 84.7233 - reconstruction_loss: 0.0076 - kl_loss: 8.4980 - r_accuracy: 21.2259\nEpoch 57/100\n85/85 [==============================] - 46s 537ms/step - loss: 83.1706 - reconstruction_loss: 0.0075 - kl_loss: 8.4954 - r_accuracy: 21.2622\nEpoch 58/100\n85/85 [==============================] - 46s 538ms/step - loss: 83.4972 - reconstruction_loss: 0.0074 - kl_loss: 8.6579 - r_accuracy: 21.3244\nEpoch 59/100\n85/85 [==============================] - 46s 539ms/step - loss: 83.0412 - reconstruction_loss: 0.0073 - kl_loss: 8.5396 - r_accuracy: 21.3915\nEpoch 60/100\n85/85 [==============================] - 46s 537ms/step - loss: 80.3920 - reconstruction_loss: 0.0072 - kl_loss: 8.6220 - r_accuracy: 21.4597\nEpoch 61/100\n85/85 [==============================] - 46s 536ms/step - loss: 81.7191 - reconstruction_loss: 0.0072 - kl_loss: 8.6057 - r_accuracy: 21.5011\nEpoch 62/100\n85/85 [==============================] - 46s 536ms/step - loss: 79.5524 - reconstruction_loss: 0.0070 - kl_loss: 8.7950 - r_accuracy: 21.5484\nEpoch 63/100\n85/85 [==============================] - 46s 536ms/step - loss: 78.8577 - reconstruction_loss: 0.0070 - kl_loss: 8.6095 - r_accuracy: 21.6152\nEpoch 64/100\n85/85 [==============================] - 46s 537ms/step - loss: 76.9484 - reconstruction_loss: 0.0069 - kl_loss: 8.8237 - r_accuracy: 21.6230\nEpoch 65/100\n85/85 [==============================] - 46s 538ms/step - loss: 77.6912 - reconstruction_loss: 0.0068 - kl_loss: 8.8376 - r_accuracy: 21.7283\nEpoch 66/100\n85/85 [==============================] - 46s 537ms/step - loss: 75.3202 - reconstruction_loss: 0.0067 - kl_loss: 8.8685 - r_accuracy: 21.7581\nEpoch 67/100\n85/85 [==============================] - 46s 538ms/step - loss: 75.2487 - reconstruction_loss: 0.0066 - kl_loss: 8.8855 - r_accuracy: 21.8200\nEpoch 68/100\n85/85 [==============================] - 46s 536ms/step - loss: 73.6078 - reconstruction_loss: 0.0066 - kl_loss: 8.8938 - r_accuracy: 21.8630\nEpoch 69/100\n85/85 [==============================] - 46s 537ms/step - loss: 73.9545 - reconstruction_loss: 0.0065 - kl_loss: 9.0351 - r_accuracy: 21.9155\nEpoch 70/100\n85/85 [==============================] - 46s 538ms/step - loss: 73.7010 - reconstruction_loss: 0.0064 - kl_loss: 9.0009 - r_accuracy: 21.9660\nEpoch 71/100\n85/85 [==============================] - 46s 538ms/step - loss: 72.2610 - reconstruction_loss: 0.0063 - kl_loss: 9.2047 - r_accuracy: 22.0077\nEpoch 72/100\n85/85 [==============================] - 46s 537ms/step - loss: 72.6355 - reconstruction_loss: 0.0063 - kl_loss: 9.1453 - r_accuracy: 22.0646\nEpoch 73/100\n85/85 [==============================] - 46s 538ms/step - loss: 69.0444 - reconstruction_loss: 0.0062 - kl_loss: 8.9668 - r_accuracy: 22.1188\nEpoch 74/100\n85/85 [==============================] - 46s 537ms/step - loss: 70.4847 - reconstruction_loss: 0.0061 - kl_loss: 9.0471 - r_accuracy: 22.1627\nEpoch 75/100\n85/85 [==============================] - 46s 537ms/step - loss: 70.4921 - reconstruction_loss: 0.0061 - kl_loss: 9.0521 - r_accuracy: 22.2050\nEpoch 76/100\n85/85 [==============================] - 46s 537ms/step - loss: 69.1954 - reconstruction_loss: 0.0060 - kl_loss: 9.1880 - r_accuracy: 22.2652\nEpoch 77/100\n85/85 [==============================] - 46s 536ms/step - loss: 67.8131 - reconstruction_loss: 0.0059 - kl_loss: 9.2071 - r_accuracy: 22.3016\nEpoch 78/100\n85/85 [==============================] - 46s 537ms/step - loss: 68.8215 - reconstruction_loss: 0.0059 - kl_loss: 9.1323 - r_accuracy: 22.3607\nEpoch 79/100\n85/85 [==============================] - 46s 538ms/step - loss: 68.4450 - reconstruction_loss: 0.0058 - kl_loss: 9.2614 - r_accuracy: 22.4015\nEpoch 80/100\n85/85 [==============================] - 46s 537ms/step - loss: 67.8214 - reconstruction_loss: 0.0058 - kl_loss: 9.2837 - r_accuracy: 22.4175\nEpoch 81/100\n85/85 [==============================] - 46s 536ms/step - loss: 67.2894 - reconstruction_loss: 0.0057 - kl_loss: 9.2758 - r_accuracy: 22.4794\nEpoch 82/100\n85/85 [==============================] - 46s 537ms/step - loss: 64.4595 - reconstruction_loss: 0.0056 - kl_loss: 9.2766 - r_accuracy: 22.5312\nEpoch 83/100\n85/85 [==============================] - 46s 537ms/step - loss: 64.7715 - reconstruction_loss: 0.0056 - kl_loss: 9.3253 - r_accuracy: 22.5773\nEpoch 84/100\n85/85 [==============================] - 46s 536ms/step - loss: 63.4671 - reconstruction_loss: 0.0055 - kl_loss: 9.4260 - r_accuracy: 22.5983\nEpoch 85/100\n85/85 [==============================] - 46s 539ms/step - loss: 65.4964 - reconstruction_loss: 0.0055 - kl_loss: 9.3533 - r_accuracy: 22.5943\nEpoch 86/100\n85/85 [==============================] - 46s 538ms/step - loss: 63.1439 - reconstruction_loss: 0.0054 - kl_loss: 9.4118 - r_accuracy: 22.7081\nEpoch 87/100\n85/85 [==============================] - 46s 538ms/step - loss: 62.4402 - reconstruction_loss: 0.0054 - kl_loss: 9.4605 - r_accuracy: 22.7274\nEpoch 88/100\n85/85 [==============================] - 46s 536ms/step - loss: 62.5161 - reconstruction_loss: 0.0054 - kl_loss: 9.5729 - r_accuracy: 22.7409\nEpoch 89/100\n85/85 [==============================] - 46s 536ms/step - loss: 64.3668 - reconstruction_loss: 0.0053 - kl_loss: 9.5559 - r_accuracy: 22.7925\nEpoch 90/100\n85/85 [==============================] - 46s 536ms/step - loss: 60.7397 - reconstruction_loss: 0.0052 - kl_loss: 9.4840 - r_accuracy: 22.8511\nEpoch 91/100\n85/85 [==============================] - 46s 536ms/step - loss: 61.3729 - reconstruction_loss: 0.0052 - kl_loss: 9.5929 - r_accuracy: 22.9190\nEpoch 92/100\n85/85 [==============================] - 46s 536ms/step - loss: 60.8412 - reconstruction_loss: 0.0051 - kl_loss: 9.5996 - r_accuracy: 22.9352\nEpoch 93/100\n85/85 [==============================] - 46s 537ms/step - loss: 60.5410 - reconstruction_loss: 0.0051 - kl_loss: 9.5221 - r_accuracy: 22.9741\nEpoch 94/100\n85/85 [==============================] - 46s 538ms/step - loss: 61.5259 - reconstruction_loss: 0.0050 - kl_loss: 9.6554 - r_accuracy: 23.0096\nEpoch 95/100\n85/85 [==============================] - 46s 537ms/step - loss: 59.1605 - reconstruction_loss: 0.0050 - kl_loss: 9.6230 - r_accuracy: 23.0342\nEpoch 96/100\n85/85 [==============================] - 46s 538ms/step - loss: 60.2205 - reconstruction_loss: 0.0050 - kl_loss: 9.6331 - r_accuracy: 23.0819\nEpoch 97/100\n85/85 [==============================] - 46s 539ms/step - loss: 58.2051 - reconstruction_loss: 0.0049 - kl_loss: 9.7559 - r_accuracy: 23.0969\nEpoch 98/100\n85/85 [==============================] - 46s 537ms/step - loss: 58.7581 - reconstruction_loss: 0.0049 - kl_loss: 9.6576 - r_accuracy: 23.1071\nEpoch 99/100\n85/85 [==============================] - 46s 535ms/step - loss: 59.0067 - reconstruction_loss: 0.0049 - kl_loss: 9.7356 - r_accuracy: 23.0971\nEpoch 100/100\n85/85 [==============================] - 46s 537ms/step - loss: 58.8775 - reconstruction_loss: 0.0049 - kl_loss: 9.6442 - r_accuracy: 23.1463\n","output_type":"stream"}]},{"cell_type":"code","source":"del x\ndel y\ndel L_df","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:37:09.876626Z","iopub.execute_input":"2023-04-19T08:37:09.877007Z","iopub.status.idle":"2023-04-19T08:37:09.969208Z","shell.execute_reply.started":"2023-04-19T08:37:09.876971Z","shell.execute_reply":"2023-04-19T08:37:09.968001Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model1.predict(test_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the images to numpy arrays\n# img1 = tf.keras.preprocessing.image.img_to_array(pred[0])\n# img2 = tf.keras.preprocessing.image.img_to_array(test_y[0])\nfinal = []\npredfinal = []\nfor i in range(600):\n    img = np.zeros((224,224,3))\n    img = pred[0]*255\n    #img = img.reshape(1, 224, 224, 3)\n    #img = np.expand_dims(img, axis=0)\n\n    img_y = np.zeros((224,224,3))\n    img_y = test_y[0]*255\n    \n    final.append(img)\n    predfinal.append(img_y)\n#img_y = img_y.reshape(1, 224, 224, 3)\n#img_y = np.expand_dims(img_y, axis=0)\nimg.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate SSIM between the two images\nssimtotal = 0\nfor i in range(600):\n    ssim_val1 = ssim(predfinal[i,:,:,0], final[i,:,:,0])\n    ssim_val2 = ssim(predfinal[i,:,:,1], final[i,:,:,0])\n    ssim_val3 = ssim(predfinal[i,:,:,2], final[i,:,:,0])\n    ssimtotal = ssimtotal + (ssim_val1 + ssim_val2 + ssim_val3)/3\n\n\n# Print the SSIM value\nprint('SSIM:', ssimtotal/600)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,16,2):\n    plt.subplot(4,4,i)\n    img = np.zeros((224,224,3))\n    img[:,:,0] = test_x[i+128]*255\n    plt.title('B&W')\n    plt.imshow(lab2rgb(img))\n    \n    plt.subplot(4,4,i+1)\n    img = pred[i+128]\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,16,2):\n    plt.subplot(4,4,i)\n    img = np.zeros((224,224,3))\n    img[:,:,0] = test_x[i]*255\n    plt.title('B&W')\n    plt.imshow(lab2rgb(img))\n    \n    plt.subplot(4,4,i+1)\n    img[:,:,1:] = test_y[i]*255\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    plt.title('Colored')\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(pred[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(pred[20])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.save_weights(\"weightsvaelab.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_weights('weights')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.score(test_x, test_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}