{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CGAN Lab","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport keras.layers as layers\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow_probability as tfp\nimport tensorflow_addons as tfa","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-18T10:04:38.517296Z","iopub.execute_input":"2023-04-18T10:04:38.518260Z","iopub.status.idle":"2023-04-18T10:04:42.225317Z","shell.execute_reply.started":"2023-04-18T10:04:38.518221Z","shell.execute_reply":"2023-04-18T10:04:42.224153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, MaxPooling2D, UpSampling2D, Concatenate\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint \nfrom keras.utils import plot_model\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.226749Z","iopub.execute_input":"2023-04-18T10:04:42.229472Z","iopub.status.idle":"2023-04-18T10:04:42.236312Z","shell.execute_reply.started":"2023-04-18T10:04:42.229430Z","shell.execute_reply":"2023-04-18T10:04:42.234820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.filters import threshold_otsu\nfrom glob import glob\nfrom scipy import misc\nfrom matplotlib.patches import Circle,Ellipse\nfrom matplotlib.patches import Rectangle","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.238006Z","iopub.execute_input":"2023-04-18T10:04:42.238783Z","iopub.status.idle":"2023-04-18T10:04:42.609103Z","shell.execute_reply.started":"2023-04-18T10:04:42.238742Z","shell.execute_reply":"2023-04-18T10:04:42.608107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport scipy.misc\nimport imageio\nfrom skimage.transform import rescale, resize\nfrom skimage.color import lab2rgb","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.612738Z","iopub.execute_input":"2023-04-18T10:04:42.613121Z","iopub.status.idle":"2023-04-18T10:04:42.677859Z","shell.execute_reply.started":"2023-04-18T10:04:42.613084Z","shell.execute_reply":"2023-04-18T10:04:42.676891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\nimport gzip","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.679533Z","iopub.execute_input":"2023-04-18T10:04:42.679906Z","iopub.status.idle":"2023-04-18T10:04:42.685214Z","shell.execute_reply.started":"2023-04-18T10:04:42.679869Z","shell.execute_reply":"2023-04-18T10:04:42.683688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.686940Z","iopub.execute_input":"2023-04-18T10:04:42.687332Z","iopub.status.idle":"2023-04-18T10:04:42.695958Z","shell.execute_reply.started":"2023-04-18T10:04:42.687292Z","shell.execute_reply":"2023-04-18T10:04:42.694906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom keras import backend as K\nimport tensorflow_addons as tfa\nimport tensorflow as tf\n\n'''batch_size= 8\nimage_size = [120, 120]\n\n\nds = image_dataset_from_directory(\n    '/kaggle/input/imagedataset/data',\n    labels=None,\n    image_size=image_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True,\n    color_mode='grayscale'\n)\n\ndef convert_to_float(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n\ndef trans1(img):\n    return tfa.image.rotate(tf.image.flip_left_right(tf.image.flip_up_down(img)),-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans2(img):\n    return tfa.image.rotate(img,-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans3(img):\n    return tfa.image.rotate(img,.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n    \nds1,ds2,ds3,ds4 = ds,ds.map(trans1),ds.map(trans2),ds.map(trans3)\n\nds = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nx = (\n    ds\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)'''","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.697637Z","iopub.execute_input":"2023-04-18T10:04:42.698004Z","iopub.status.idle":"2023-04-18T10:04:42.710168Z","shell.execute_reply.started":"2023-04-18T10:04:42.697967Z","shell.execute_reply":"2023-04-18T10:04:42.708956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ab_path = \"/kaggle/input/image-colorization/ab/ab/ab1.npy\"\nl_path = \"/kaggle/input/image-colorization/l/gray_scale.npy\"","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.712179Z","iopub.execute_input":"2023-04-18T10:04:42.713312Z","iopub.status.idle":"2023-04-18T10:04:42.719416Z","shell.execute_reply.started":"2023-04-18T10:04:42.713274Z","shell.execute_reply":"2023-04-18T10:04:42.718342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ab_df = np.load(ab_path)[0:3000]\nL_df = np.load(l_path)[0:3000]\ndataset = (L_df,ab_df )\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:04:42.721008Z","iopub.execute_input":"2023-04-18T10:04:42.721413Z","iopub.status.idle":"2023-04-18T10:05:01.323611Z","shell.execute_reply.started":"2023-04-18T10:04:42.721375Z","shell.execute_reply":"2023-04-18T10:05:01.322462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lab_to_rgb(L, ab):\n    \"\"\"\n    Takes an image or a batch of images and converts from LAB space to RGB\n    \"\"\"\n    L = L  * 100\n    ab = (ab - 0.5) * 128 * 2\n    Lab = np.concatenate([L, ab], dim=2).numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = Image.lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:01.326939Z","iopub.execute_input":"2023-04-18T10:05:01.327313Z","iopub.status.idle":"2023-04-18T10:05:01.336769Z","shell.execute_reply.started":"2023-04-18T10:05:01.327283Z","shell.execute_reply":"2023-04-18T10:05:01.335534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,16,2):\n    plt.subplot(4,4,i)\n    img = np.zeros((224,224,3))\n    img[:,:,0] = L_df[i]\n    plt.title('B&W')\n    plt.imshow(lab2rgb(img))\n    \n    plt.subplot(4,4,i+1)\n    img[:,:,1:] = ab_df[i]\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    plt.title('Colored')\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:01.337764Z","iopub.execute_input":"2023-04-18T10:05:01.338096Z","iopub.status.idle":"2023-04-18T10:05:06.292798Z","shell.execute_reply.started":"2023-04-18T10:05:01.338045Z","shell.execute_reply":"2023-04-18T10:05:06.291342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 224\nbatch_size = 64\nINPUT_DIM = (img_size,img_size,1)\nZ_DIM = 64","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:06.294350Z","iopub.execute_input":"2023-04-18T10:05:06.294870Z","iopub.status.idle":"2023-04-18T10:05:06.302443Z","shell.execute_reply.started":"2023-04-18T10:05:06.294811Z","shell.execute_reply":"2023-04-18T10:05:06.301196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ab_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:06.308800Z","iopub.execute_input":"2023-04-18T10:05:06.309594Z","iopub.status.idle":"2023-04-18T10:05:06.316703Z","shell.execute_reply.started":"2023-04-18T10:05:06.309556Z","shell.execute_reply":"2023-04-18T10:05:06.315675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"x = []\ny = []\ndef read_images(data): #method to read images\n    for i in range(len(data)):\n        rgb_image = Image.open( data[i] ).resize( ( img_size , img_size ) )\n        # Normalize the RGB image array\n        rgb_img_array = (np.asarray( rgb_image ) ) / 255\n        gray_image = rgb_image.convert( 'L' )\n        # Normalize the grayscale image array\n        gray_img_array = ( np.asarray( gray_image ).reshape( ( img_size , img_size , 1 ) ) ) / 255\n        # Append both the image arrays\n        x.append( gray_img_array )\n        y.append( rgb_img_array )\n    return x,y\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:06.318304Z","iopub.execute_input":"2023-04-18T10:05:06.318916Z","iopub.status.idle":"2023-04-18T10:05:06.327173Z","shell.execute_reply.started":"2023-04-18T10:05:06.318881Z","shell.execute_reply":"2023-04-18T10:05:06.325717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"x, y = read_images(data) #calling readimage\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:06.329233Z","iopub.execute_input":"2023-04-18T10:05:06.330216Z","iopub.status.idle":"2023-04-18T10:05:06.336618Z","shell.execute_reply.started":"2023-04-18T10:05:06.330009Z","shell.execute_reply":"2023-04-18T10:05:06.335582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = x = (L_df/255).astype('float32') \ny = (ab_df/255).astype('float32') ","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:06.337995Z","iopub.execute_input":"2023-04-18T10:05:06.338701Z","iopub.status.idle":"2023-04-18T10:05:08.207722Z","shell.execute_reply.started":"2023-04-18T10:05:06.338667Z","shell.execute_reply":"2023-04-18T10:05:08.206676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(y[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:08.209442Z","iopub.execute_input":"2023-04-18T10:05:08.210046Z","iopub.status.idle":"2023-04-18T10:05:08.214973Z","shell.execute_reply.started":"2023-04-18T10:05:08.210000Z","shell.execute_reply":"2023-04-18T10:05:08.213544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split( x , y , test_size=0.1, random_state=42 )","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:08.216658Z","iopub.execute_input":"2023-04-18T10:05:08.217034Z","iopub.status.idle":"2023-04-18T10:05:08.732697Z","shell.execute_reply.started":"2023-04-18T10:05:08.216998Z","shell.execute_reply":"2023-04-18T10:05:08.731523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        mean_mu, log_var = inputs\n        epsilon = tf.random.normal(shape=tf.shape(mean_mu), mean=0., stddev=1.) \n        return mean_mu + tf.math.exp(log_var/2)*epsilon ","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:08.734509Z","iopub.execute_input":"2023-04-18T10:05:08.734954Z","iopub.status.idle":"2023-04-18T10:05:08.741927Z","shell.execute_reply.started":"2023-04-18T10:05:08.734909Z","shell.execute_reply":"2023-04-18T10:05:08.740572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrelu = tf.nn.selu","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:08.743762Z","iopub.execute_input":"2023-04-18T10:05:08.744488Z","iopub.status.idle":"2023-04-18T10:05:08.752220Z","shell.execute_reply.started":"2023-04-18T10:05:08.744446Z","shell.execute_reply":"2023-04-18T10:05:08.751078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_generator_model():\n\n    inputs = tf.keras.layers.Input( shape=( img_size , img_size , 1 ) )\n\n    conv1 = tf.keras.layers.Conv2D( 16 , kernel_size=( 5 , 5 ) , strides=1 )( inputs )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n\n    conv2 = tf.keras.layers.Conv2D( 32 , kernel_size=( 5 , 5 ) , strides=1)( conv1 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n\n    conv3 = tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n\n    bottleneck = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='tanh' , padding='same' )( conv3 )\n\n    concat_1 = tf.keras.layers.Concatenate()( [ bottleneck , conv3 ] )\n    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_1 )\n    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( conv_up_3 )\n    conv_up_3 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_3 )\n\n    concat_2 = tf.keras.layers.Concatenate()( [ conv_up_3 , conv2 ] )\n    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_2 )\n    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( conv_up_2 )\n    conv_up_2 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_2 )\n\n    concat_3 = tf.keras.layers.Concatenate()( [ conv_up_2 , conv1 ] )\n    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( concat_3 )\n    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( conv_up_1 )\n    conv_up_1 = tf.keras.layers.Conv2DTranspose( 2 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu')( conv_up_1 )\n\n    model = tf.keras.models.Model( inputs , conv_up_1 )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:08.755022Z","iopub.execute_input":"2023-04-18T10:05:08.755908Z","iopub.status.idle":"2023-04-18T10:05:08.773594Z","shell.execute_reply.started":"2023-04-18T10:05:08.755866Z","shell.execute_reply":"2023-04-18T10:05:08.772339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = get_generator_model()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:08.776562Z","iopub.execute_input":"2023-04-18T10:05:08.776996Z","iopub.status.idle":"2023-04-18T10:05:11.816227Z","shell.execute_reply.started":"2023-04-18T10:05:08.776958Z","shell.execute_reply":"2023-04-18T10:05:11.815391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_discriminator_model():\n    \n    input1 = tf.keras.layers.Input( shape=( img_size , img_size , 2 ) )\n    input2 = tf.keras.layers.Input( shape=( img_size , img_size , 2 ) )\n\n    \n    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 7 , 7 ) , strides=1 )( input1 )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n    conv1 = tf.keras.layers.MaxPooling2D()( conv1 )\n    conv2 = tf.keras.layers.Conv2D( 32 , kernel_size=( 7 , 7 ) , strides=1 )( input2 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n    conv2 = tf.keras.layers.MaxPooling2D()( conv2 )\n    \n    conv1 = tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1 )( conv1 )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n    conv1 = tf.keras.layers.MaxPooling2D()( conv1 )\n    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n    conv2 = tf.keras.layers.MaxPooling2D()( conv2 )\n    \n    conv1 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv1 )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n    conv1 = tf.keras.layers.MaxPooling2D()( conv1 )\n    conv2 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n    conv2 = tf.keras.layers.MaxPooling2D()( conv2 )\n    \n    conv1 = tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 )( conv1 )\n    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n    conv1 = tf.keras.layers.MaxPooling2D()( conv1 )\n    conv2 = tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n    conv2 = tf.keras.layers.MaxPooling2D()( conv2 )\n    \n    concat1 = tf.keras.layers.Concatenate()( [ conv1 , conv2 ] )\n    \n    flatten = tf.keras.layers.Flatten()( concat1 )\n    \n    dense1 = tf.keras.layers.Dense( 512, activation='relu'  )( flatten )\n    dense1 = tf.keras.layers.Dense( 128 , activation='relu' )( dense1 )\n    dense1 = tf.keras.layers.Dense( 16 , activation='relu' )( dense1 )\n    dense1 = tf.keras.layers.Dense( 1 , activation='sigmoid' )( dense1 )\n    \n    model = tf.keras.models.Model( [input1, input2] , dense1 )\n    \n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:11.817454Z","iopub.execute_input":"2023-04-18T10:05:11.817825Z","iopub.status.idle":"2023-04-18T10:05:11.869915Z","shell.execute_reply.started":"2023-04-18T10:05:11.817777Z","shell.execute_reply":"2023-04-18T10:05:11.868339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"def get_discriminator_model():\n    layers = [\n        tf.keras.layers.Conv2D( 32 , kernel_size=( 7 , 7 ) , strides=1 , activation='relu' , input_shape=( 224 , 224 , 2 ) ),\n        tf.keras.layers.Conv2D( 32 , kernel_size=( 7, 7 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense( 512, activation='relu'  )  ,\n        tf.keras.layers.Dense( 128 , activation='relu' ) ,\n        tf.keras.layers.Dense( 16 , activation='relu' ) ,\n        tf.keras.layers.Dense( 1 , activation='sigmoid' ) \n    ]\n    model = tf.keras.models.Sequential( layers )\n    return model\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:11.871858Z","iopub.execute_input":"2023-04-18T10:05:11.872653Z","iopub.status.idle":"2023-04-18T10:05:11.890351Z","shell.execute_reply.started":"2023-04-18T10:05:11.872569Z","shell.execute_reply":"2023-04-18T10:05:11.889152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = get_discriminator_model()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:11.892234Z","iopub.execute_input":"2023-04-18T10:05:11.892686Z","iopub.status.idle":"2023-04-18T10:05:12.094453Z","shell.execute_reply.started":"2023-04-18T10:05:11.892647Z","shell.execute_reply":"2023-04-18T10:05:12.093383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 0.001","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.095995Z","iopub.execute_input":"2023-04-18T10:05:12.096421Z","iopub.status.idle":"2023-04-18T10:05:12.102244Z","shell.execute_reply.started":"2023-04-18T10:05:12.096380Z","shell.execute_reply":"2023-04-18T10:05:12.101004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy()\nmse = tf.keras.losses.MeanSquaredError()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.104191Z","iopub.execute_input":"2023-04-18T10:05:12.105037Z","iopub.status.idle":"2023-04-18T10:05:12.113043Z","shell.execute_reply.started":"2023-04-18T10:05:12.104938Z","shell.execute_reply":"2023-04-18T10:05:12.111802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output) , real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output) , fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    gen_loss = cross_entropy(tf.ones_like(fake_output) , fake_output)\n    return gen_loss","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.115092Z","iopub.execute_input":"2023-04-18T10:05:12.115487Z","iopub.status.idle":"2023-04-18T10:05:12.124103Z","shell.execute_reply.started":"2023-04-18T10:05:12.115428Z","shell.execute_reply":"2023-04-18T10:05:12.122699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def r_accuracy(img_original, img_reconstructed):\n    mse = tf.reduce_mean((img_original - img_reconstructed) ** 2)\n    pixel_max = 1.0\n    psnr = 20 * tf.math.log(pixel_max / tf.math.sqrt(mse))/tf.math.log(10.0)\n    return psnr","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.125365Z","iopub.execute_input":"2023-04-18T10:05:12.126258Z","iopub.status.idle":"2023-04-18T10:05:12.134954Z","shell.execute_reply.started":"2023-04-18T10:05:12.126217Z","shell.execute_reply":"2023-04-18T10:05:12.133497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN(keras.Model):\n    def __init__(self, generator, discriminator, gen_op=keras.optimizers.Adam(learning_rate = lr), disc_op=keras.optimizers.Adam(learning_rate = lr/10), **kwargs):\n        super(GAN, self).__init__(**kwargs)\n        self.generator = generator\n        self.discriminator = discriminator\n        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n        self.disc_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n        self.r_accuracy_tracker = keras.metrics.Mean(name=\"r_accuracy\")\n        self.r_accuracy = r_accuracy\n        self.disc_loss = discriminator_loss\n        self.gen_loss = generator_loss\n        \n        self.gen_optimizer = gen_op\n        self.disc_optimizer = disc_op\n        \n    def call(self,x):\n        reconstruction = self.generator(x)\n        return reconstruction\n\n    \n    @property\n    def metrics(self):\n        return [\n            self.gen_loss_tracker,\n            self.disc_loss_tracker,\n            self.r_accuracy_tracker,\n        ]\n\n    def train_step(self, data):\n        x, y = data\n        with tf.GradientTape() as disc_tape:\n            reconstruction = self.generator(x)\n            real_output = self.discriminator([y, y])\n            fake_output = self.discriminator([y, reconstruction])\n            disc_loss = self.disc_loss(real_output, fake_output)\n            \n\n        grad_disc = disc_tape.gradient(disc_loss, self.discriminator.trainable_weights)\n        \n        self.disc_optimizer.apply_gradients(zip(grad_disc, self.discriminator.trainable_weights))\n        \n        with tf.GradientTape() as gen_tape:\n            reconstruction = self.generator(x)\n            fake_output = self.discriminator([y, reconstruction])\n            gen_loss = self.gen_loss(fake_output) \n            r_accuracy = self.r_accuracy(y, reconstruction)\n            \n        \n        grad_gen = gen_tape.gradient(gen_loss, self.generator.trainable_weights)\n\n        self.gen_optimizer.apply_gradients(zip(grad_gen, self.generator.trainable_weights))\n        \n        self.gen_loss_tracker.update_state(gen_loss)\n        self.disc_loss_tracker.update_state(disc_loss)\n        self.r_accuracy_tracker.update_state(r_accuracy)\n        return {\n            \"gen_loss\": self.gen_loss_tracker.result(),\n            \"disc_loss\": self.disc_loss_tracker.result(),\n            \"r_accuracy\": self.r_accuracy_tracker.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.136667Z","iopub.execute_input":"2023-04-18T10:05:12.137424Z","iopub.status.idle":"2023-04-18T10:05:12.159648Z","shell.execute_reply.started":"2023-04-18T10:05:12.137307Z","shell.execute_reply":"2023-04-18T10:05:12.158576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = GAN(generator,discriminator)\nmodel1.compile(optimizer=keras.optimizers.Adam(learning_rate = lr))","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.161917Z","iopub.execute_input":"2023-04-18T10:05:12.162629Z","iopub.status.idle":"2023-04-18T10:05:12.196627Z","shell.execute_reply.started":"2023-04-18T10:05:12.162594Z","shell.execute_reply":"2023-04-18T10:05:12.195695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model1.fit(train_x, train_y, epochs=50, batch_size=16, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T10:05:12.197975Z","iopub.execute_input":"2023-04-18T10:05:12.198473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"del x\ndel y\ndel L_df\ndel ab_df\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model1.predict(test_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,16,2):\n    plt.subplot(4,4,i)\n    img = np.zeros((224,224,3))\n    img[:,:,0] = test_x[i]*255\n    plt.title('B&W')\n    plt.imshow(lab2rgb(img))\n    \n    plt.subplot(4,4,i+1)\n    img[:,:,1:] = pred[i]*255\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    plt.title('Colored')\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,16,2):\n    plt.subplot(4,4,i)\n    img = np.zeros((224,224,3))\n    img[:,:,0] = test_x[i]*255\n    plt.title('B&W')\n    plt.imshow(lab2rgb(img))\n    \n    plt.subplot(4,4,i+1)\n    img[:,:,1:] = test_y[i]*255\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    plt.title('Colored')\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom skimage import io, img_as_float\nfrom skimage.metrics import structural_similarity as ssim","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the images to numpy arrays\n# img1 = tf.keras.preprocessing.image.img_to_array(pred[0])\n# img2 = tf.keras.preprocessing.image.img_to_array(test_y[0])\nfinal = []\npredfinal = []\nfor i in range(600):\n    img = np.zeros((224,224,3))\n    img[:,:,0] = test_x[i]*255\n    img[:,:,1:] = pred[i]*255\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    #img = img.reshape(1, 224, 224, 3)\n    #img = np.expand_dims(img, axis=0)\n    img_y = np.zeros((224,224,3))\n    img_y[:,:,0] = test_x[0]*255\n    img_y[:,:,1:] = test_y[0]*255\n    img_y = img_y.astype('uint8')\n    img_y = cv2.cvtColor(img_y, cv2.COLOR_LAB2RGB)\n    final.append(img)\n    predfinal.append(img_y)\n#img_y = img_y.reshape(1, 224, 224, 3)\n#img_y = np.expand_dims(img_y, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate SSIM between the two images\nssimtotal = 0\nfor i in range(600):\n    ssim_val1 = ssim(predfinal[i,:,:,0], final[i,:,:,0])\n    ssim_val2 = ssim(predfinal[i,:,:,1], final[i,:,:,0])\n    ssim_val3 = ssim(predfinal[i,:,:,2], final[i,:,:,0])\n    ssimtotal = ssimtotal + (ssim_val1 + ssim_val2 + ssim_val3)/3\n\n\n# Print the SSIM value\nprint('SSIM:', ssimtotal/600)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}